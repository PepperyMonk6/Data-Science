{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week_3_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDUW3f4ws8GN"
      },
      "source": [
        "# Week 3: Introduction to Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMdKEr5Ds8GQ"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWRfTL3s8GT"
      },
      "source": [
        "## Activation functions\n",
        "Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (“fired”) or not, based on whether each neuron’s input is relevant for the model’s prediction. Activation functions also help normalize the output of each neuron.\n",
        "\n",
        "An additional aspect of activation functions is that they must be computationally efficient because they are calculated across thousands or even millions of neurons for each data sample. Modern neural networks use a technique called backpropagation to train the model, which places an increased computational strain on the activation function, and its derivative function.\n",
        "\n",
        "The popular activation functions and their derivatives are represented:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HED2gGb5s8GU"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def derivative(f, z, eps=0.000001):\n",
        "    return (f(z + eps) - f(z - eps))/(2 * eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhzPoinvs8GY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "3dfb8df0-7a19-4d78-f340-99c0efa227f9"
      },
      "source": [
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "plt.figure(figsize=(11,4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
        "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
        "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"center right\", fontsize=14)\n",
        "plt.title(\"Activation functions\", fontsize=14)\n",
        "plt.axis([-5, 5, -1.2, 1.2])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
        "plt.plot(0, 0, \"ro\", markersize=5)\n",
        "plt.plot(0, 0, \"rx\", markersize=10)\n",
        "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
        "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "#plt.legend(loc=\"center right\", fontsize=14)\n",
        "plt.title(\"Derivatives\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.2, 1.2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKydiwpPs8Gd"
      },
      "source": [
        "## NN for MNIST\n",
        "\n",
        "In this section we will build an MLP with TensorFlow, and we will implement Minibatch Gradient Descent to train it on the MNIST dataset. The first step is the construction phase, building the TensorFlow graph. The second step is the execution phase, where you actually run the graph to train the model.\n",
        "\n",
        "First we need to import the tensorflow library. Then we must specify the number of inputs and outputs, and set the number of hidden neurons in each layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-2ZX2HtSoC"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZeDWOWDVRSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80350d32-6f1e-484b-a410-1e05dfd4c6ca"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWpEItDvs8Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5c7e08-b7d2-4744-c981-80d18f30b6d3"
      },
      "source": [
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "x_valid, x_train = x_train[:5000], x_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epZbDtxhTgqw"
      },
      "source": [
        "# Building a model with Softmax\n",
        "Softmax extends this idea into a multi-class world. That is, Softmax assigns decimal probabilities to each class in a multi-class problem. Those decimal probabilities must add up to 1.0. This additional constraint helps training converge more quickly than it otherwise would.\n",
        "\n",
        "For example, returning to the image analysis we saw in Figure 1, Softmax might produce the following likelihoods of an image belonging to a particular class:\n",
        "\n",
        "![softmax](https://raw.githubusercontent.com/hqsiswiliam/surrey_ai_lab_dataset/master/SoftmaxLayer.svg)\n",
        "\n",
        "- reference: [Multi-Class Neural Networks: Softmax](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbgT5FLBs8Gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b725eb62-f50f-4f39-9f1b-cbcf48def910"
      },
      "source": [
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 128\n",
        "n_outputs = 10\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28*28,)),\n",
        "        layers.Dense(n_hidden1, name='hidden1', activation='relu'),\n",
        "        layers.Dense(n_hidden2, name='hidden2', activation='relu'),\n",
        "        layers.Dense(n_outputs, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden1 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " hidden2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KNFY-1Ts8G0"
      },
      "source": [
        "Now that we have the neural network model ready to go, we need to define the cost function that we will use to train it. We will use cross entropy, cross entropy will penalize models that estimate a low probability for the target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DehyyC6eWBXS"
      },
      "source": [
        "crossentropy = keras.losses.CategoricalCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2DJvngWs8G3"
      },
      "source": [
        "We have the neural network model, we have the cost function, and now we need to define a GradientDescentOptimizer that will tweak the model parameters to minimize the cost function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiAFtlNrWZ0G"
      },
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "accuracy = keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gfAyBOs8HG"
      },
      "source": [
        "And now we can train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct4cOljSXFZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a833db23-5c5c-4a49-e662-3b3dd4d5cf6c"
      },
      "source": [
        "model.compile(loss=crossentropy, optimizer=optimizer, metrics=[accuracy])\n",
        "model.fit(x_train,y_train,batch_size=128,epochs=10,validation_data=(x_valid,y_valid), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "430/430 [==============================] - 4s 5ms/step - loss: 2.2355 - categorical_accuracy: 0.1849 - val_loss: 2.1125 - val_categorical_accuracy: 0.3682\n",
            "Epoch 2/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 1.9811 - categorical_accuracy: 0.5182 - val_loss: 1.8497 - val_categorical_accuracy: 0.6086\n",
            "Epoch 3/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 1.7079 - categorical_accuracy: 0.6622 - val_loss: 1.5635 - val_categorical_accuracy: 0.6920\n",
            "Epoch 4/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 1.4325 - categorical_accuracy: 0.7225 - val_loss: 1.2986 - val_categorical_accuracy: 0.7446\n",
            "Epoch 5/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 1.1975 - categorical_accuracy: 0.7651 - val_loss: 1.0896 - val_categorical_accuracy: 0.7850\n",
            "Epoch 6/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 1.0187 - categorical_accuracy: 0.7939 - val_loss: 0.9358 - val_categorical_accuracy: 0.8096\n",
            "Epoch 7/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 0.8874 - categorical_accuracy: 0.8138 - val_loss: 0.8227 - val_categorical_accuracy: 0.8292\n",
            "Epoch 8/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 0.7905 - categorical_accuracy: 0.8275 - val_loss: 0.7385 - val_categorical_accuracy: 0.8438\n",
            "Epoch 9/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 0.7176 - categorical_accuracy: 0.8384 - val_loss: 0.6746 - val_categorical_accuracy: 0.8484\n",
            "Epoch 10/10\n",
            "430/430 [==============================] - 2s 4ms/step - loss: 0.6614 - categorical_accuracy: 0.8469 - val_loss: 0.6244 - val_categorical_accuracy: 0.8572\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5990640ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouR3znp7s8HJ"
      },
      "source": [
        "Now that the neural network is trained, you can use it to make predictions. To do that, you can reuse the same construction phase, but change the execution phase like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyaQaQLps8HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0f0dd4-60d4-409d-98e1-c908afc07951"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "# Since y_pred only output probabilities over classes, we retrieve the one with max probability\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "print(\"Predicted classes:\", y_pred)\n",
        "print(\"Actual classes:   \", y_test_argmax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: [7 2 1 ... 4 5 6]\n",
            "Actual classes:    [7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpeZIHzKs8HS"
      },
      "source": [
        "## <font color='red'> Task1</font>\n",
        "\n",
        "**Task 1:** Train your own MLP on the MNIST dataset and see if you can get over 95% precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpjbEH9GyW0I"
      },
      "source": [
        "**This can be achieved by many ways, here we just replace SGD optmiser by Adam optimiser.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BYu4UALdbIy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFjIj2Ysm-3G"
      },
      "source": [
        "# Challenge Part: Tumour classification\n",
        "We have a dataset containing measurements of breast tumours. This is a classification task, unlike last week's which was regression.\n",
        "\n",
        "- Labels:\n",
        "  - 'B' for benign (noncancerous) \n",
        "  - 'M' for malignant (cancerous)\n",
        "- Notes:\n",
        "  - You can use loss related to binary\n",
        "  - Different activation functions might impact your model\n",
        "  - You could look at feature-wise normalisation, which may help your model's performance, [using utility functions from scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
        "  - The Kaggle link is: https://www.kaggle.com/t/3cd15e8c85774fd88ae312a9783db8f1\n",
        "  - **Please also set your team name to your URN on Kaggle. You may need to return to lab 2's competition page and do this too.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up environment variables for Kaggle (same as in last lab):"
      ],
      "metadata": {
        "id": "wnka6XU38JQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'illyagloba'  # Your Kaggle username\n",
        "os.environ['KAGGLE_KEY'] = 'bfaa0cf3192da654476cf05ceeb4130c'  # Your Kaggle API key\n",
        "os.environ['URN'] = '6604778'  # Your URN: submissions without a URN will not count"
      ],
      "metadata": {
        "id": "eGWOsPI78F_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset.\n",
        "\n",
        "Note we invoke Kaggle using `!python`, this means it uses Python 3 and Kaggle 1.5.12. Calling `!kaggle` uses Python 2 and Kaggle 1.5.4. The `kaggle` script defaults to Python 2, hence this difference."
      ],
      "metadata": {
        "id": "7d-FBmLX8OxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle -v\n",
        "!python2 -m pip show kaggle"
      ],
      "metadata": {
        "id": "TMXYpVS1HiEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52741b27-44c3-4551-9a13-c7bb28a3c736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API 1.5.4\n",
            "Name: kaggle\n",
            "Version: 1.5.4\n",
            "Summary: Kaggle API\n",
            "Home-page: https://github.com/Kaggle/kaggle-api\n",
            "Author: Kaggle\n",
            "Author-email: support@kaggle.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python2.7/dist-packages\n",
            "Requires: requests, tqdm, certifi, python-dateutil, urllib3, six, python-slugify\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /usr/local/bin/kaggle -v\n",
        "!python3 -m pip show kaggle"
      ],
      "metadata": {
        "id": "RDejONFnG3mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9387b2-4962-4275-f5c6-41e9e7caca8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API 1.5.12\n",
            "Name: kaggle\n",
            "Version: 1.5.12\n",
            "Summary: Kaggle API\n",
            "Home-page: https://github.com/Kaggle/kaggle-api\n",
            "Author: Kaggle\n",
            "Author-email: support@kaggle.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: python-slugify, six, tqdm, urllib3, requests, python-dateutil, certifi\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /usr/local/bin/kaggle competitions download -c uos-com2028-21-22-lab3 --force\n",
        "!unzip uos-com2028-21-22-lab3.zip"
      ],
      "metadata": {
        "id": "7zLwXmegGM8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e461d73-ec0d-4d7d-cff8-74def6cdb715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading uos-com2028-21-22-lab3.zip to /content\n",
            "\r  0% 0.00/46.9k [00:00<?, ?B/s]\n",
            "\r100% 46.9k/46.9k [00:00<00:00, 39.0MB/s]\n",
            "Archive:  uos-com2028-21-22-lab3.zip\n",
            "  inflating: BreastCancerTest.csv    \n",
            "  inflating: BreastCancerTrain.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to load the dataset:"
      ],
      "metadata": {
        "id": "uyDRROakI8jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_bc = pd.read_csv('BreastCancerTrain.csv')\n",
        "test_bc = pd.read_csv('BreastCancerTest.csv')\n",
        "\n",
        "print(f'Training set sample (target=weight): \\n{train_bc[:10]}\\n\\n')\n",
        "print(f'Testing set sample (target=weight): \\n{test_bc[:3]}\\n\\n')\n",
        "\n",
        "# Return all columns that are not the target, 'diagnosis', as a numpy array\n",
        "X_train_bc = train_bc.loc[:, train_bc.columns != 'diagnosis'].values\n",
        "X_test_bc = test_bc.loc[:, test_bc.columns != 'id'].values\n",
        "\n",
        "# Return only the 'diagnosis' column as a numpy array\n",
        "y_train_bc = train_bc.loc[:, 'diagnosis'].values\n",
        "\n",
        "# We need to convert the dataset target classes from strings 'M' and 'B' to a \n",
        "# boolean indicating 'Is Malignant?'\n",
        "y_train_bc_bool = y_train_bc == 'M'\n",
        "\n",
        "# If you want to use one-hot encoding:\n",
        "y_train_bc_onehot = to_categorical(y_train_bc_bool, 2)\n",
        "\n",
        "print('Training sample shape', X_train_bc.shape, 'example:', X_train_bc[0])\n",
        "print('Training target shape one-hot', y_train_bc_onehot.shape, 'example:', y_train_bc_onehot[0])\n",
        "print('Training target shape bool', y_train_bc_bool.shape, 'example:', y_train_bc_bool[0])\n",
        "print('Testing sample shape', X_test_bc.shape, 'example:', X_test_bc[0])"
      ],
      "metadata": {
        "id": "Sl0-SerOAWKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5120fc0e-5154-4468-b548-3b0405218a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set sample (target=weight): \n",
            "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
            "0         B       13.270  ...          0.2027                  0.06206\n",
            "1         B       14.060  ...          0.2523                  0.06609\n",
            "2         B       10.290  ...          0.2226                  0.08283\n",
            "3         B        9.738  ...          0.3105                  0.08151\n",
            "4         B       15.710  ...          0.2723                  0.07071\n",
            "5         B       11.370  ...          0.3267                  0.06994\n",
            "6         B       12.560  ...          0.2121                  0.07188\n",
            "7         B        8.878  ...          0.2434                  0.07431\n",
            "8         B       14.690  ...          0.2827                  0.09208\n",
            "9         M       18.220  ...          0.2812                  0.08198\n",
            "\n",
            "[10 rows x 31 columns]\n",
            "\n",
            "\n",
            "Testing set sample (target=weight): \n",
            "   id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
            "0   0       15.730  ...          0.2557                  0.08181\n",
            "1   1        8.734  ...          0.2445                  0.08865\n",
            "2   2       15.320  ...          0.3258                  0.11910\n",
            "\n",
            "[3 rows x 31 columns]\n",
            "\n",
            "\n",
            "Training sample shape (447, 30) example: [1.327e+01 1.476e+01 8.474e+01 5.517e+02 7.355e-02 5.055e-02 3.261e-02\n",
            " 2.648e-02 1.386e-01 5.318e-02 4.057e-01 1.153e+00 2.701e+00 3.635e+01\n",
            " 4.481e-03 1.038e-02 1.358e-02 1.082e-02 1.069e-02 1.435e-03 1.636e+01\n",
            " 2.235e+01 1.045e+02 8.306e+02 1.006e-01 1.238e-01 1.350e-01 1.001e-01\n",
            " 2.027e-01 6.206e-02]\n",
            "Training target shape one-hot (447, 2) example: [1. 0.]\n",
            "Training target shape bool (447,) example: False\n",
            "Testing sample shape (113, 30) example: [1.573e+01 1.128e+01 1.028e+02 7.472e+02 1.043e-01 1.299e-01 1.191e-01\n",
            " 6.211e-02 1.784e-01 6.259e-02 1.630e-01 3.871e-01 1.143e+00 1.387e+01\n",
            " 6.034e-03 1.820e-02 3.336e-02 1.067e-02 1.175e-02 2.256e-03 1.701e+01\n",
            " 1.420e+01 1.125e+02 8.543e+02 1.541e-01 2.979e-01 4.004e-01 1.452e-01\n",
            " 2.557e-01 8.181e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build your classifier!"
      ],
      "metadata": {
        "id": "sAK2ghI3LHaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here: build your NN classifier\n",
        "n_inputs = 30  # MNIST\n",
        "n_hidden1 = 4096\n",
        "n_hidden2 = 2048\n",
        "n_hidden3 = 1024\n",
        "n_hidden4 = 512\n",
        "n_hidden5 = 256\n",
        "n_outputs = 2\n",
        "\n",
        "print(X_train_bc.shape)\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(30,)),\n",
        "        layers.Dense(n_hidden1, name='hidden1', activation='relu'),\n",
        "        layers.Dense(n_hidden2, name='hidden2', activation='relu'),\n",
        "        layers.Dense(n_hidden1, name='hidden3', activation='relu'),\n",
        "        layers.Dense(n_hidden1, name='hidden4', activation='relu'),\n",
        "        layers.Dense(n_hidden1, name='hidden5', activation='relu'),\n",
        "        layers.Dense(n_outputs, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "crossentropy = keras.losses.CategoricalCrossentropy()\n",
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "accuracy = keras.metrics.CategoricalAccuracy()\n",
        "precision = keras.metrics.Precision()\n",
        "\n",
        "model.compile(loss=crossentropy, optimizer=optimizer, metrics=[accuracy, precision])\n",
        "model.fit(X_train_bc,y_train_bc_onehot,batch_size=128,epochs=450,validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Set predictions to the output of your model\n",
        "predictions = model.predict(X_test_bc)"
      ],
      "metadata": {
        "id": "zeiJVZWdLGqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6f2d86-4a21-408d-a68c-1ef3c465a414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(447, 30)\n",
            "Epoch 1/450\n",
            "3/3 [==============================] - 2s 148ms/step - loss: 56.5866 - categorical_accuracy: 0.5686 - precision_1: 0.5686 - val_loss: 22.3037 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 2/450\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 13.1517 - categorical_accuracy: 0.4650 - precision_1: 0.4650 - val_loss: 0.5698 - val_categorical_accuracy: 0.7778 - val_precision_1: 0.7778\n",
            "Epoch 3/450\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.9799 - categorical_accuracy: 0.5938 - precision_1: 0.5938 - val_loss: 7.1812 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 4/450\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 4.8580 - categorical_accuracy: 0.4482 - precision_1: 0.4482 - val_loss: 0.5446 - val_categorical_accuracy: 0.8111 - val_precision_1: 0.8111\n",
            "Epoch 5/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.6221 - categorical_accuracy: 0.7899 - precision_1: 0.7899 - val_loss: 5.6764 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 6/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.4079 - categorical_accuracy: 0.5406 - precision_1: 0.5406 - val_loss: 3.9016 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 7/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.4842 - categorical_accuracy: 0.7003 - precision_1: 0.7003 - val_loss: 0.3640 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 8/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.0407 - categorical_accuracy: 0.6611 - precision_1: 0.6611 - val_loss: 2.3252 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 9/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.4733 - categorical_accuracy: 0.4818 - precision_1: 0.4818 - val_loss: 0.9555 - val_categorical_accuracy: 0.6556 - val_precision_1: 0.6556\n",
            "Epoch 10/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.9694 - categorical_accuracy: 0.6106 - precision_1: 0.6106 - val_loss: 1.2064 - val_categorical_accuracy: 0.3556 - val_precision_1: 0.3556\n",
            "Epoch 11/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.8024 - categorical_accuracy: 0.5630 - precision_1: 0.5630 - val_loss: 0.5596 - val_categorical_accuracy: 0.7667 - val_precision_1: 0.7667\n",
            "Epoch 12/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.5109 - categorical_accuracy: 0.7675 - precision_1: 0.7675 - val_loss: 0.5378 - val_categorical_accuracy: 0.7111 - val_precision_1: 0.7111\n",
            "Epoch 13/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4119 - categorical_accuracy: 0.8291 - precision_1: 0.8291 - val_loss: 0.3021 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 14/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3488 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.4514 - val_categorical_accuracy: 0.7889 - val_precision_1: 0.7889\n",
            "Epoch 15/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4187 - categorical_accuracy: 0.8375 - precision_1: 0.8375 - val_loss: 0.2681 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 16/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3064 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2755 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 17/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3835 - categorical_accuracy: 0.8599 - precision_1: 0.8599 - val_loss: 1.1176 - val_categorical_accuracy: 0.4111 - val_precision_1: 0.4111\n",
            "Epoch 18/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6145 - categorical_accuracy: 0.6891 - precision_1: 0.6891 - val_loss: 0.4968 - val_categorical_accuracy: 0.8000 - val_precision_1: 0.8000\n",
            "Epoch 19/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.7216 - categorical_accuracy: 0.6387 - precision_1: 0.6387 - val_loss: 0.5395 - val_categorical_accuracy: 0.7000 - val_precision_1: 0.7000\n",
            "Epoch 20/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4092 - categorical_accuracy: 0.8319 - precision_1: 0.8319 - val_loss: 0.2765 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 21/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3407 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.6892 - val_categorical_accuracy: 0.5667 - val_precision_1: 0.5667\n",
            "Epoch 22/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.5487 - categorical_accuracy: 0.7339 - precision_1: 0.7339 - val_loss: 0.2907 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 23/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3087 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.2463 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 24/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2759 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.3028 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 25/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5518 - categorical_accuracy: 0.7423 - precision_1: 0.7423 - val_loss: 0.3364 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 26/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3213 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2537 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 27/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2771 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2348 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 28/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3100 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.5649 - val_categorical_accuracy: 0.7111 - val_precision_1: 0.7111\n",
            "Epoch 29/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4502 - categorical_accuracy: 0.7983 - precision_1: 0.7983 - val_loss: 0.3671 - val_categorical_accuracy: 0.8222 - val_precision_1: 0.8222\n",
            "Epoch 30/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3065 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2739 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 31/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2617 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2302 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 32/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2436 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2496 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 33/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3074 - categorical_accuracy: 0.8768 - precision_1: 0.8768 - val_loss: 0.4935 - val_categorical_accuracy: 0.8111 - val_precision_1: 0.8111\n",
            "Epoch 34/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6724 - categorical_accuracy: 0.6947 - precision_1: 0.6947 - val_loss: 0.2993 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 35/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2902 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2449 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 36/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3646 - categorical_accuracy: 0.8599 - precision_1: 0.8599 - val_loss: 0.5059 - val_categorical_accuracy: 0.7111 - val_precision_1: 0.7111\n",
            "Epoch 37/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4664 - categorical_accuracy: 0.7731 - precision_1: 0.7731 - val_loss: 0.3409 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 38/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2761 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2284 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 39/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2466 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2263 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 40/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3346 - categorical_accuracy: 0.8683 - precision_1: 0.8683 - val_loss: 0.3488 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 41/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3476 - categorical_accuracy: 0.8683 - precision_1: 0.8683 - val_loss: 0.3421 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 42/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3831 - categorical_accuracy: 0.8347 - precision_1: 0.8347 - val_loss: 0.3752 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 43/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3597 - categorical_accuracy: 0.8711 - precision_1: 0.8711 - val_loss: 0.2332 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 44/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2447 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2660 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 45/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2507 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2419 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 46/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.5747 - categorical_accuracy: 0.7423 - precision_1: 0.7423 - val_loss: 0.7668 - val_categorical_accuracy: 0.5556 - val_precision_1: 0.5556\n",
            "Epoch 47/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4210 - categorical_accuracy: 0.8067 - precision_1: 0.8067 - val_loss: 0.2705 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 48/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2941 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.4596 - val_categorical_accuracy: 0.7889 - val_precision_1: 0.7889\n",
            "Epoch 49/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2597 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2279 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 50/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2473 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.3275 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 51/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4817 - categorical_accuracy: 0.7675 - precision_1: 0.7675 - val_loss: 0.2939 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 52/450\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2583 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2307 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 53/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2370 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.3204 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 54/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2806 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2198 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 55/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2263 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2100 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 56/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3809 - categorical_accuracy: 0.8487 - precision_1: 0.8487 - val_loss: 0.6066 - val_categorical_accuracy: 0.6444 - val_precision_1: 0.6444\n",
            "Epoch 57/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3940 - categorical_accuracy: 0.8123 - precision_1: 0.8123 - val_loss: 0.2421 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 58/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2358 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2150 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 59/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2250 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2157 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 60/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2380 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.3198 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 61/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3218 - categorical_accuracy: 0.8627 - precision_1: 0.8627 - val_loss: 0.4511 - val_categorical_accuracy: 0.7778 - val_precision_1: 0.7778\n",
            "Epoch 62/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3481 - categorical_accuracy: 0.8459 - precision_1: 0.8459 - val_loss: 0.2718 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 63/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2596 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.3167 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 64/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2412 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2137 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 65/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2373 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.3875 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 66/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3060 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.2586 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 67/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3218 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.2291 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 68/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2440 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2258 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 69/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2557 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.2929 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 70/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3331 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.2534 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 71/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2719 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.4233 - val_categorical_accuracy: 0.8222 - val_precision_1: 0.8222\n",
            "Epoch 72/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3036 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.2285 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 73/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2791 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.4382 - val_categorical_accuracy: 0.7889 - val_precision_1: 0.7889\n",
            "Epoch 74/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2597 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.2315 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 75/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2235 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2153 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 76/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3257 - categorical_accuracy: 0.8739 - precision_1: 0.8739 - val_loss: 0.4819 - val_categorical_accuracy: 0.7444 - val_precision_1: 0.7444\n",
            "Epoch 77/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3149 - categorical_accuracy: 0.8655 - precision_1: 0.8655 - val_loss: 0.2852 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 78/450\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2469 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2243 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 79/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2690 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2312 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 80/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2204 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2058 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 81/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2151 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2498 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 82/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2403 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2304 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 83/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2297 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2149 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 84/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2883 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.4472 - val_categorical_accuracy: 0.7889 - val_precision_1: 0.7889\n",
            "Epoch 85/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3708 - categorical_accuracy: 0.8543 - precision_1: 0.8543 - val_loss: 0.2181 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 86/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2212 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2455 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 87/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2539 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2538 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 88/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3410 - categorical_accuracy: 0.8655 - precision_1: 0.8655 - val_loss: 0.2774 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 89/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2397 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2589 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 90/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3909 - categorical_accuracy: 0.8263 - precision_1: 0.8263 - val_loss: 0.3036 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 91/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2873 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.2357 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 92/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2134 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2151 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 93/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2112 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2647 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 94/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3488 - categorical_accuracy: 0.8375 - precision_1: 0.8375 - val_loss: 0.2261 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 95/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2234 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2086 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 96/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2658 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.3609 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 97/450\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2288 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2113 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 98/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2726 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.6067 - val_categorical_accuracy: 0.6444 - val_precision_1: 0.6444\n",
            "Epoch 99/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3186 - categorical_accuracy: 0.8599 - precision_1: 0.8599 - val_loss: 0.2165 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 100/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2224 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2209 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 101/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2591 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.3058 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 102/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2369 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2095 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 103/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2173 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2389 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 104/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3099 - categorical_accuracy: 0.8768 - precision_1: 0.8768 - val_loss: 0.2415 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 105/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2493 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2583 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 106/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2223 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2810 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 107/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3030 - categorical_accuracy: 0.8459 - precision_1: 0.8459 - val_loss: 0.2237 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 108/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2705 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.3108 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 109/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3105 - categorical_accuracy: 0.8768 - precision_1: 0.8768 - val_loss: 0.2235 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 110/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3004 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.3426 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 111/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3050 - categorical_accuracy: 0.8936 - precision_1: 0.8936 - val_loss: 0.2270 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 112/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2624 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.5436 - val_categorical_accuracy: 0.6889 - val_precision_1: 0.6889\n",
            "Epoch 113/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3337 - categorical_accuracy: 0.8459 - precision_1: 0.8459 - val_loss: 0.2165 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 114/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2319 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2768 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 115/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2393 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2106 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 116/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2195 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2899 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 117/450\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2441 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2412 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 118/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2745 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.3503 - val_categorical_accuracy: 0.8444 - val_precision_1: 0.8444\n",
            "Epoch 119/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2200 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2667 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 120/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2465 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2411 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 121/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2393 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2278 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 122/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2005 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2098 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 123/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2680 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.5870 - val_categorical_accuracy: 0.6889 - val_precision_1: 0.6889\n",
            "Epoch 124/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4229 - categorical_accuracy: 0.8039 - precision_1: 0.8039 - val_loss: 0.2339 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 125/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2223 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2095 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 126/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2044 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2078 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 127/450\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2336 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2506 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 128/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2703 - categorical_accuracy: 0.8768 - precision_1: 0.8768 - val_loss: 0.2767 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 129/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3586 - categorical_accuracy: 0.8403 - precision_1: 0.8403 - val_loss: 0.2316 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 130/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2178 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2394 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 131/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2082 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2082 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 132/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2027 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2129 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 133/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1988 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2159 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 134/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2445 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2638 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 135/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2475 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.2705 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 136/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2236 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2157 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 137/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2002 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2336 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 138/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2242 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2281 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 139/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2609 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.5718 - val_categorical_accuracy: 0.7000 - val_precision_1: 0.7000\n",
            "Epoch 140/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.3445 - categorical_accuracy: 0.8347 - precision_1: 0.8347 - val_loss: 0.2541 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 141/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2590 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.3736 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 142/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3100 - categorical_accuracy: 0.8711 - precision_1: 0.8711 - val_loss: 0.2120 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 143/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1997 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.3839 - val_categorical_accuracy: 0.8222 - val_precision_1: 0.8222\n",
            "Epoch 144/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2930 - categorical_accuracy: 0.8796 - precision_1: 0.8796 - val_loss: 0.3141 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 145/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3448 - categorical_accuracy: 0.8347 - precision_1: 0.8347 - val_loss: 0.2324 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 146/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2619 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2110 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 147/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2054 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2165 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 148/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2027 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2150 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 149/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1969 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.3718 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 150/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2546 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2067 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 151/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2018 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2076 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 152/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2030 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2160 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 153/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1942 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2119 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 154/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1938 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2298 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 155/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2018 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2091 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 156/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2274 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2569 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 157/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2056 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2076 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 158/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2027 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2081 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 159/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2628 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.2495 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 160/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2127 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2290 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 161/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2248 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.3529 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 162/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4116 - categorical_accuracy: 0.8263 - precision_1: 0.8263 - val_loss: 0.2162 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 163/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2218 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2109 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 164/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2320 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2482 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 165/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2335 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2682 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 166/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2538 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.3427 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 167/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3422 - categorical_accuracy: 0.8627 - precision_1: 0.8627 - val_loss: 0.2918 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 168/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2251 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2100 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 169/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2003 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2099 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 170/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2027 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2263 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 171/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1983 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.3030 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 172/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3052 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2156 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 173/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2119 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2141 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 174/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2042 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2403 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 175/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2580 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2736 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 176/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2111 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2291 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 177/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1934 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2352 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 178/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2637 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2563 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 179/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2244 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2063 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 180/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2877 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.3415 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 181/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2409 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.2134 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 182/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2261 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2970 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 183/450\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2631 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.2164 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 184/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2039 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2298 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 185/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1999 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2114 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 186/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1919 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2082 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 187/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2071 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2502 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 188/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2304 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.5424 - val_categorical_accuracy: 0.7111 - val_precision_1: 0.7111\n",
            "Epoch 189/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3134 - categorical_accuracy: 0.8487 - precision_1: 0.8487 - val_loss: 0.2109 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 190/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2157 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2474 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 191/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2954 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2081 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 192/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2025 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2458 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 193/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2071 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.3284 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 194/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3465 - categorical_accuracy: 0.8487 - precision_1: 0.8487 - val_loss: 0.2437 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 195/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2480 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2122 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 196/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2019 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2731 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 197/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2193 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2083 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 198/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1987 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2556 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 199/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1972 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2262 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 200/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3145 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.3334 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 201/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2259 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2249 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 202/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1967 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2757 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 203/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2726 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.2812 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 204/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2298 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2507 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 205/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2073 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2191 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 206/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1929 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2168 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 207/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2043 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2170 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 208/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2038 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.3566 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 209/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2696 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2297 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 210/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2339 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2298 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 211/450\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2398 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2642 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 212/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2748 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2226 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 213/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2239 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2552 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 214/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2154 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2131 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 215/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1891 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2116 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 216/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1963 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2311 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 217/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2401 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2472 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 218/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1945 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2187 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 219/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1992 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2647 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 220/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2520 - categorical_accuracy: 0.8964 - precision_1: 0.8964 - val_loss: 0.2515 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 221/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4527 - categorical_accuracy: 0.8039 - precision_1: 0.8039 - val_loss: 0.2336 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 222/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2454 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2140 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 223/450\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2808 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.4095 - val_categorical_accuracy: 0.8222 - val_precision_1: 0.8222\n",
            "Epoch 224/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2890 - categorical_accuracy: 0.8739 - precision_1: 0.8739 - val_loss: 0.2146 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 225/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2316 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.3722 - val_categorical_accuracy: 0.8333 - val_precision_1: 0.8333\n",
            "Epoch 226/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2487 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2191 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 227/450\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2107 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2190 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 228/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2406 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2343 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 229/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2007 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2164 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 230/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2301 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2202 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 231/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2136 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2073 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 232/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1992 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2416 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 233/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2361 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2575 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 234/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3347 - categorical_accuracy: 0.8571 - precision_1: 0.8571 - val_loss: 0.2237 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 235/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1937 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2127 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 236/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1937 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2094 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 237/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2057 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2703 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 238/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2607 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2260 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 239/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2217 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2072 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 240/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1960 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2109 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 241/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1940 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2175 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 242/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1903 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2237 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 243/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1872 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2085 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 244/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1940 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2747 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 245/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2385 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2096 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 246/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1894 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2327 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 247/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1973 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2158 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 248/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1951 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2252 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 249/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2366 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2233 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 250/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2038 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2165 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 251/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2016 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2788 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 252/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1949 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2118 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 253/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1948 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2126 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 254/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2355 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.3113 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 255/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3341 - categorical_accuracy: 0.8599 - precision_1: 0.8599 - val_loss: 0.2171 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 256/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2092 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2134 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 257/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1898 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2254 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 258/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2068 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2103 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 259/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1994 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2278 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 260/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1977 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2268 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 261/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2536 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2523 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 262/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1999 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2108 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 263/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2524 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2830 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 264/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2253 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2096 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 265/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1913 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.3574 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 266/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2756 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2132 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 267/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2174 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2122 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 268/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1915 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2155 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 269/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1892 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2122 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 270/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2138 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2461 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 271/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2093 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2111 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 272/450\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2058 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2478 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 273/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3328 - categorical_accuracy: 0.8571 - precision_1: 0.8571 - val_loss: 0.2556 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 274/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2277 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2096 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 275/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2348 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2191 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 276/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1977 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2441 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 277/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2778 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.2616 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 278/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2247 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2462 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 279/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2258 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2097 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 280/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2123 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2476 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 281/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2562 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2439 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 282/450\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2248 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2146 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 283/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2288 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2691 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 284/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1979 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2482 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 285/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1911 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2152 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 286/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2843 - categorical_accuracy: 0.8796 - precision_1: 0.8796 - val_loss: 0.2940 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 287/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2377 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2084 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 288/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1901 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2138 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 289/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1865 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2240 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 290/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2605 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2689 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 291/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2168 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2094 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 292/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2145 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.5162 - val_categorical_accuracy: 0.7556 - val_precision_1: 0.7556\n",
            "Epoch 293/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3087 - categorical_accuracy: 0.8431 - precision_1: 0.8431 - val_loss: 0.2129 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 294/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2104 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2413 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 295/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1960 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2210 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 296/450\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1918 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2237 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 297/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1890 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2325 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 298/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1989 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2406 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 299/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3700 - categorical_accuracy: 0.8403 - precision_1: 0.8403 - val_loss: 0.2258 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 300/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2078 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2160 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 301/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1983 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2475 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 302/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2803 - categorical_accuracy: 0.8768 - precision_1: 0.8768 - val_loss: 0.2142 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 303/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2352 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2451 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 304/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2691 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2416 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 305/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3009 - categorical_accuracy: 0.8739 - precision_1: 0.8739 - val_loss: 0.2338 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 306/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2095 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2758 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 307/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2587 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2071 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 308/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1921 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2110 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 309/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2020 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2194 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 310/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1879 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2152 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 311/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1857 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2147 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 312/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1947 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2174 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 313/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1960 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2449 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 314/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2533 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2334 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 315/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1910 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2396 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 316/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2739 - categorical_accuracy: 0.8908 - precision_1: 0.8908 - val_loss: 0.2394 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 317/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2048 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2583 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 318/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1897 - categorical_accuracy: 0.9384 - precision_1: 0.9384 - val_loss: 0.2274 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 319/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2754 - categorical_accuracy: 0.8852 - precision_1: 0.8852 - val_loss: 0.2358 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 320/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1916 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2107 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 321/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1875 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2252 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 322/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2018 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2171 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 323/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1852 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2151 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 324/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1845 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2138 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 325/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1898 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2165 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 326/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1970 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2348 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 327/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2521 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2438 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 328/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2218 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2852 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 329/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2423 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2275 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 330/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2162 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2555 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 331/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2162 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2054 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 332/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1878 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2107 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 333/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1951 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2253 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 334/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2330 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2817 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 335/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2212 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2213 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 336/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2047 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2480 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 337/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2803 - categorical_accuracy: 0.8936 - precision_1: 0.8936 - val_loss: 0.2691 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 338/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2136 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2472 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 339/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2040 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.3323 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 340/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3270 - categorical_accuracy: 0.8683 - precision_1: 0.8683 - val_loss: 0.2071 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 341/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2102 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2605 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 342/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2582 - categorical_accuracy: 0.9020 - precision_1: 0.9020 - val_loss: 0.2293 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 343/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2005 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2171 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 344/450\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2095 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2132 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 345/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1867 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2181 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 346/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1849 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2378 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 347/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2381 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2742 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 348/450\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2852 - categorical_accuracy: 0.8824 - precision_1: 0.8824 - val_loss: 0.2210 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 349/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2315 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2347 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 350/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1978 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2114 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 351/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2002 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2508 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 352/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1810 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2328 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 353/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2348 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2481 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 354/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2047 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2080 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 355/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1798 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2314 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 356/450\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1919 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2094 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 357/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1798 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2097 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 358/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2067 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2297 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 359/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1909 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2227 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 360/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2033 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2641 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 361/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2174 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2121 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 362/450\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1827 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2163 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 363/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2111 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2641 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 364/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2216 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2340 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 365/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2364 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2068 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 366/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2044 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2446 - val_categorical_accuracy: 0.8889 - val_precision_1: 0.8889\n",
            "Epoch 367/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1918 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2180 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 368/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2344 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.4829 - val_categorical_accuracy: 0.7667 - val_precision_1: 0.7667\n",
            "Epoch 369/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3050 - categorical_accuracy: 0.8543 - precision_1: 0.8543 - val_loss: 0.2112 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 370/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1920 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2128 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 371/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1916 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2311 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 372/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2003 - categorical_accuracy: 0.9104 - precision_1: 0.9104 - val_loss: 0.2298 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 373/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2267 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2337 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 374/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2340 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2124 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 375/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1884 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2100 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 376/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1811 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2143 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 377/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1828 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2122 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 378/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1804 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2131 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 379/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1838 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.3002 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 380/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2013 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2213 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 381/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1799 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2293 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 382/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2805 - categorical_accuracy: 0.8739 - precision_1: 0.8739 - val_loss: 0.2906 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 383/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4300 - categorical_accuracy: 0.7843 - precision_1: 0.7843 - val_loss: 0.2166 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 384/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2231 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.3404 - val_categorical_accuracy: 0.8556 - val_precision_1: 0.8556\n",
            "Epoch 385/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2964 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2086 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 386/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1973 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2100 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 387/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1846 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2173 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 388/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2276 - categorical_accuracy: 0.8992 - precision_1: 0.8992 - val_loss: 0.2405 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 389/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2089 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2165 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 390/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2002 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2290 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 391/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2858 - categorical_accuracy: 0.8880 - precision_1: 0.8880 - val_loss: 0.2125 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 392/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2137 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2149 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 393/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1900 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2197 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 394/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1861 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2414 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 395/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2103 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2148 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 396/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1935 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2117 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 397/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1801 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2221 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 398/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1805 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2306 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 399/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1927 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2397 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 400/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1994 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2302 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 401/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2234 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2403 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 402/450\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1882 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2460 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 403/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1940 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2140 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 404/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1862 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2146 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 405/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1850 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2395 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 406/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2116 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2345 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 407/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2325 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2173 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 408/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2134 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2207 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 409/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1817 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2109 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 410/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1883 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2199 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 411/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1810 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2126 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 412/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2033 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2099 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 413/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1974 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2346 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 414/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1968 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2334 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 415/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2026 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2200 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 416/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1900 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2119 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 417/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1792 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2117 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 418/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1791 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2152 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 419/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2138 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.3645 - val_categorical_accuracy: 0.8444 - val_precision_1: 0.8444\n",
            "Epoch 420/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1998 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2214 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 421/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1921 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2626 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 422/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2210 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2113 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 423/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1847 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2336 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 424/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1900 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2572 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 425/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2404 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2108 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 426/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1911 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2228 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 427/450\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1840 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2161 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 428/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1758 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2142 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 429/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1962 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2232 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 430/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2330 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.3197 - val_categorical_accuracy: 0.8778 - val_precision_1: 0.8778\n",
            "Epoch 431/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2061 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2431 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 432/450\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1920 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2380 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 433/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1811 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2133 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 434/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2280 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2043 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 435/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1834 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2102 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 436/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1790 - categorical_accuracy: 0.9300 - precision_1: 0.9300 - val_loss: 0.2186 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 437/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1906 - categorical_accuracy: 0.9328 - precision_1: 0.9328 - val_loss: 0.2536 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 438/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2335 - categorical_accuracy: 0.9160 - precision_1: 0.9160 - val_loss: 0.2617 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 439/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2196 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2232 - val_categorical_accuracy: 0.9333 - val_precision_1: 0.9333\n",
            "Epoch 440/450\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2162 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2076 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 441/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1782 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2210 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 442/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2115 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.2373 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 443/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2009 - categorical_accuracy: 0.9076 - precision_1: 0.9076 - val_loss: 0.2152 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 444/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1831 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2532 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 445/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2353 - categorical_accuracy: 0.9188 - precision_1: 0.9188 - val_loss: 0.2514 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 446/450\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2474 - categorical_accuracy: 0.9132 - precision_1: 0.9132 - val_loss: 0.2304 - val_categorical_accuracy: 0.9000 - val_precision_1: 0.9000\n",
            "Epoch 447/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1965 - categorical_accuracy: 0.9216 - precision_1: 0.9216 - val_loss: 0.2143 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n",
            "Epoch 448/450\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2147 - categorical_accuracy: 0.9244 - precision_1: 0.9244 - val_loss: 0.3509 - val_categorical_accuracy: 0.8667 - val_precision_1: 0.8667\n",
            "Epoch 449/450\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2622 - categorical_accuracy: 0.9048 - precision_1: 0.9048 - val_loss: 0.2238 - val_categorical_accuracy: 0.9222 - val_precision_1: 0.9222\n",
            "Epoch 450/450\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1773 - categorical_accuracy: 0.9272 - precision_1: 0.9272 - val_loss: 0.2388 - val_categorical_accuracy: 0.9111 - val_precision_1: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will need to convert the output of your model to be 'M' or 'B' for each test sample. This depends on if you used boolean or one-hot encoding for the targets (or probabilities). You may need to adjust the examples below for your model."
      ],
      "metadata": {
        "id": "htkqHg0gNFVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you used one-hot encoding:\n",
        "final_predictions = ['M' if prediction == 1 else 'B' for prediction in np.argmax(predictions, axis=1)]\n",
        "\n",
        "# Uncomment if you boolean encoding:\n",
        "#final_predictions = ['M' if prediction == 1 else 'B' for prediction in predictions]"
      ],
      "metadata": {
        "id": "VK2YbNYc89FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to save the output to a CSV file:"
      ],
      "metadata": {
        "id": "x-qzgsJa--7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={'Diagnosis': final_predictions}).to_csv('predictions.csv', index_label='Id')"
      ],
      "metadata": {
        "id": "Nf78jspwLS_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To resubmit, run your model cell (after changes), the CSV file cell and the cell below."
      ],
      "metadata": {
        "id": "u7Ki6OK1NYFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /usr/local/bin/kaggle competitions submit -m $URN -c uos-com2028-21-22-lab3 -f predictions.csv"
      ],
      "metadata": {
        "id": "bZZBxuNKNQ5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd541537-3499-4101-8034-df84392c431b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 581/581 [00:01<00:00, 418B/s]\n",
            "Successfully submitted to COM2028 21/22 Lab 3"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your score should soon [show up on Kaggle](https://www.kaggle.com/c/uos-com2028-21-22-lab3/submissions)..."
      ],
      "metadata": {
        "id": "u1px_xxPNThv"
      }
    }
  ]
}