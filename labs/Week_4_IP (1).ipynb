{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week_4_IP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__V0NiMgvNS5"
      },
      "source": [
        "# Week 4: Image Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To8xIL51vNS-"
      },
      "source": [
        "Many major packages in python provide interfaces to manipulate imagesand videos. The most useful packages are numpy, scipy and scikit-image. All these packages provide the necessary functions and classes to work with signals, images, and develop some machine learning and AI techniques.\n",
        "\n",
        "The first thing we have to do is load an image to a numpy array that holds all the required information to represent this image. We can represent an 8-bit grayscale image with a size of $n \\times m$ pixels, as an array (matrix) $I$ that has size $n \\times m$ ($n$ rows and $m$ columns). Each cell of the array $I$ holds a value from $0$ to $255$ which are all the possible values an 8-bit variable can take ($2^8=256$). A value of $0$ means that this pixel is black, and a value of 255 means that the pixel is white.\n",
        "\n",
        "![Figure1](https://raw.githubusercontent.com/wOOL/COM2028/master/W1/pixelmap_gray.png)\n",
        "\n",
        "In this figure, we can see a pixelmap of a random grayscale image of size 10x10. The programming structure that holds this image in memory is an array of size 10x10. {Note that the pixel values are all in the range $[0,255]$ with 0 being black and 255 being white.}\n",
        "\n",
        "![Figure2](https://raw.githubusercontent.com/wOOL/COM2028/master/W1/pixelmap_rgb.png)\n",
        "\n",
        "In this figure, we can see a pixelmap of a random RGB image of size 10x10. The programming structure that holds this image in memory is an array of size 10x10x3. Each one of the 3 dimensions are similar to the array that holds the data for a grayscale image. The first dimension holds the data regarding the red values of the image, the second of the green values, and the third the values related to the blue colour. There are other colour spaces that represent colours in different ways than the amount of red, green, blue that each pixel has (such as LUV, HSV, HSL etc.) but in this lab we will only use the RGB model. Using other models is straightforward if one knows how to work with RGB. {Each colour is produced by mixing specific weights of the three main components $r,g,b$.} \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBcNCQmvNS_"
      },
      "source": [
        "## 1. Accessing and manipulating image pixels in python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKai3EjSvNTA"
      },
      "source": [
        "The first exercise deals with the basics of how to load an image from a file to a numpy array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJbyoklmvNTA"
      },
      "source": [
        "from skimage.io import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXjGd0LhvNTB"
      },
      "source": [
        "#read a grayscale image to a numpy array\n",
        "gray = imread('https://raw.githubusercontent.com/hqsiswiliam/surrey_ai_lab_dataset/master/flower-gray-s.png')\n",
        "gray = gray[:,:,:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeDkHgE0vNTC"
      },
      "source": [
        "print('gray shape => '+str(gray.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwtQoT9MvNTC"
      },
      "source": [
        "rgb = imread('https://raw.githubusercontent.com/hqsiswiliam/surrey_ai_lab_dataset/master/flower-s.png')\n",
        "rgb = rgb[:,:,:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viFsiWdIvNTC"
      },
      "source": [
        "print('rgb shape =>'+str(rgb.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_cgNBtyvNTD"
      },
      "source": [
        "# print the first pixel values for both images\n",
        "print('rgb[0,0,:] => '+str(rgb[0,0,:]))\n",
        "print('gray[0,0] => '+str(gray[0,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mir12J2gvNTD"
      },
      "source": [
        "The size (shape) of the gray flower image can also be written as (256,256,1), while the size of the colour RGB flower image is (256,256,3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUCItd0SvNTE"
      },
      "source": [
        "## 2. Converting from RGB to Grayscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuiUkg5qvNTE"
      },
      "source": [
        "In this exercise we will see how to convert an image from RGB to grayscale, and we will also see how to run a function over all the pixels of an image, avoiding the usual $for$ loops and using some built-in numpy methods.\n",
        "\n",
        "To convert an image from RGB to grayscale, we have to combine the information that are available in the three channels into a single channel. This is done by taking a combination of the three values r,g,b and producing a new value that represents the intensity. \n",
        "\n",
        "So in general the way to compute: \n",
        "\n",
        "\\begin{equation}\n",
        "Y = \\alpha R + \\beta G + \\gamma B, \\; with \\; 0 \\leq \\alpha,\\beta,\\gamma \\leq 1\n",
        "\\end{equation}\n",
        "\n",
        "There are many combinations of values that give results that are consistent with the properties of human vision, and two commonly used triads[1] are \\{$\\alpha = 0.2125$, $\\beta =0.7154$, $\\gamma =0.0721$\\} and \\{$\\alpha = 0.299$, $\\beta =0.587$, $\\gamma =0.114$\\} {There is also the obvious choice of $\\alpha =\\beta =\\gamma =\\frac{1}{3}$ but this is not commonly used.}. \n",
        "\n",
        "Of course in order to convert the whole numpy array from an RGB array of size (256,256,3) to a grayscale array of size (256,256) we have to run the conversion formula through all the pixels of the image ($256\\times256 = 65536$ conversions).\n",
        "\n",
        "[1]. ITU-R, Parameter values for the hdtv standards for production and international programme exchange, http://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.709-3-199802-S!!PDF-E.pdf \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9PpEV79vNTE"
      },
      "source": [
        "import numpy as np\n",
        "# this is a new import - it is the graphics backend \n",
        "# that allow to show and save plots and images.\n",
        "import matplotlib.pyplot as plt\n",
        "# need to define the colormap (grayscale - vs rgb)\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zu1-TI_vNTF"
      },
      "source": [
        "plt.imshow(rgb,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x70Vc-DvNTF"
      },
      "source": [
        "# get the dimensions of the rgb image\n",
        "(w,h,dims) = rgb.shape\n",
        "# create an empty array of size (w,h)\n",
        "grayscale = np.zeros((w,h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNUMRDXvNTF"
      },
      "source": [
        "for x in range(w):\n",
        "    for y in range(h):\n",
        "        r = rgb[x,y,0]\n",
        "        g = rgb[x,y,1]\n",
        "        b = rgb[x,y,2]\n",
        "        grayscale[x,y] = 0.2125*r + 0.7154*g + 0.0721*b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUaFzunqvNTG"
      },
      "source": [
        "plt.imshow(grayscale,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_U5dlnXvNTG"
      },
      "source": [
        "Python itself is not a fast language like C or C++. But the core modules of the numpy and scipy are written in C. That means that everything that involves pure nympy operations, should be more or less as fast as the equivalent compiled C code. Numpy provides many tools that can be used to eliminate the need for pure python code, and these tools should be used when someone writes a computationally expensive program. \n",
        "\n",
        "For example, the double $for$ (for each row,column) loop that computes the rgb->grayscale convertion in the above code can be avoided. To do this, we can use the advanced indexing tools of numpy.\n",
        "\n",
        "We can perform many arithmetical and logical operations directly on the numpy objects. First we have to split the rgb array into its' three components r,g,b and then we can define a new array grayscale which is the same as the result of the double for loop in above code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BStW9cs361aR"
      },
      "source": [
        "### <font color='red'>Task 1</font>\n",
        "- Converting **RGB** pixels to **grayscale** pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxUnQpQ9vNTH"
      },
      "source": [
        "R = rgb[:,:,0] # [:] means all the points in that direction\n",
        "G = rgb[:,:,1]\n",
        "# Your code here\n",
        "B = \n",
        "gray = 0.2125*R + # You need to complete with G and B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4HSyHDsvNTI"
      },
      "source": [
        "plt.imshow(gray,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuRK1ovuvNTI"
      },
      "source": [
        "With this syntax, the execution time is around 900 times faster than the for loop version. Keep in mind that the R G B are full 2d arrays not scalar values. Is there an increase in speed from loops to indexing?\n",
        "\n",
        "\n",
        "Indexing is a powerful way to avoid for loops, and it should be used whenever it is possible for fast code. {More about the numpy indexing together with some examples here: http://docs.scipy.org/doc/numpy/user/basics.indexing.html }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vCSbhFIvNTI"
      },
      "source": [
        "## 3. Manipulating images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOOwJ2CYvNTI"
      },
      "source": [
        "### 3.1 Image flipping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KlEqJswvNTJ"
      },
      "source": [
        "By manipulating the raw pixels of the image we can perform some effects like image flipping. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-10W0-SgvNTJ"
      },
      "source": [
        "flower = gray.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAv-jt_xvNTJ"
      },
      "source": [
        "(w,h) = flower.shape\n",
        "print(w,h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dur8M5ZovNTK"
      },
      "source": [
        "#create an empty version of our image\n",
        "flipped_vertical = np.zeros_like(flower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iREjQwvNTK"
      },
      "source": [
        "#loop through the whole image and reverse x values\n",
        "for x in range(w):\n",
        "    for y in range(h):\n",
        "        flipped_vertical[w-x-1,y] = flower[x,y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqUsvGhvNTK"
      },
      "source": [
        "#show everything\n",
        "plt.imshow(flipped_vertical,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WI9qI5vNTK"
      },
      "source": [
        "By using the numpy advanced indexing. As in numpy A[0,0] means the element in the first row and the first column, and  x[:] means all the elements, x[::-1] means all the elements reversed. \n",
        "\n",
        "Use the time measuring snippets to compare the executing speed with the double for loop version (Check https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time for \"%%timeit\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56KKv5jSvNTL"
      },
      "source": [
        "flipped_vertical_arr = flower[::-1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-5kOXFvNTL"
      },
      "source": [
        "# Show everything\n",
        "plt.imshow(flipped_vertical_arr,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_LCR1u2vNTL"
      },
      "source": [
        "### <font color='red'>Task 2</font>\n",
        "Modify the above code so that it flips the image horizontally instead of vertically.\n",
        "\n",
        "Hint: Please refer to what we did in flipping vertical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuWLu5J9vNTL"
      },
      "source": [
        "# Complete the code for task 2\n",
        "flipped_horizontally_arr ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMYnZoAKvNTL"
      },
      "source": [
        "# Show everything\n",
        "plt.imshow(flipped_horizontally_arr,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1jtnDuDvNTM"
      },
      "source": [
        "### <font color='red'>Task 3</font>\n",
        "If $x$ is the value of any pixel in (0, 255), the inverse can be computed using the function $f(x) = 255 - x$. Modify the code so that it shows the inverse of an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXGg7n9tvNTM"
      },
      "source": [
        "# Complete the code for task 3\n",
        "inverse = ??\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rmLSHb2vNTM"
      },
      "source": [
        "# Show everything\n",
        "plt.imshow(inverse,cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P98eQgA_vNTM"
      },
      "source": [
        "### 3.2 Image contrast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8PM2JL-vNTM"
      },
      "source": [
        "We can adjust the contrast of the image, if we multiple each pixel with a value $a$, that we will call $adjustment\\; factor$. intuitively, if $a>1$ then we will enhance the image contrast, and if $a<1$ then we will reduce the image contrast. \n",
        "\n",
        "One technical problem that we will find this time, is the overflow. When we manipulate 8-bit images, some times our calculations make the pixels get values higher than 255 and lower than 0. For uint8 grayscale images, this will produce an overflow. There are many solutions, but the simplest one is the following:\n",
        "\n",
        "\n",
        "* Load the image as a float array instead of uint8\n",
        "* Perform the manipulations\n",
        "* Convert the values that are above 255 to 255\n",
        "* Convert the values that are below 0 to 0\n",
        "* Present the image as a uint8 array\n",
        "\n",
        "Also in this example, we will learn how to present multiple plots in the same figure using matplotlib's subplot functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qpIY3JZvNTM"
      },
      "source": [
        "# create the new empty versions of our original image\n",
        "darkened = np.zeros_like(flower)\n",
        "lightened = np.zeros_like(flower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j_pF-O9vNTN"
      },
      "source": [
        "a_darken = 0.2\n",
        "a_lighten = 1.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqjlcqwqvNTN"
      },
      "source": [
        "# Your code here: set up the a for both cases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwOKwznxvNTN"
      },
      "source": [
        "# fix the overflows\n",
        "darkened[darkened>255]=255\n",
        "darkened[darkened<0]=0\n",
        "lightened[lightened>255]=255\n",
        "lightened[lightened<0]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBbyArwuvNTN"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.subplot(121, aspect='equal')\n",
        "plt.imshow(lightened.astype(np.uint8),cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.title('a='+str(a_lighten))\n",
        "plt.subplot(122, aspect='equal')\n",
        "plt.imshow(darkened.astype(np.uint8),cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.title('a='+str(a_darken))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S0-N2kDvNTO"
      },
      "source": [
        "The following codes are the ones that perform the overflow protection. Remove them to see what the result is without overflow handling, and try to interpret it.\n",
        "\n",
        "```python\n",
        "darkened[darkened>255]=255\n",
        "darkened[darkened<0]=0\n",
        "lightened[lightened>255]=255\n",
        "lightened[lightened<0]=0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfHqAZAHvNTO"
      },
      "source": [
        "### 3.3 Averaging images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcGwXwyEvNTO"
      },
      "source": [
        "To blend images together, we just have to create a new image, where each element is the mean value of the respective elements in the two input images. \n",
        "\n",
        "In general, to create a new image $A$, that is a blend of the images $I_1,I_2,I_3,...,I_n$, \n",
        "\n",
        "\\begin{equation}\n",
        "A = \\sum_{k=1}^{n} w_k \\times I_k  \\; \\textbf{(element-wise)}\n",
        "\\end{equation}\n",
        "\n",
        "The weights $w_k$ define the amount of contribution of each image in the final averaged image, and the sum of all the weifht should add up to 1.\n",
        "\n",
        "To demonstrate the averaging of images, we will use the Olivetti dataset which contains 400 face images. We are going to compute how the average face looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW8PCe3dvNTO"
      },
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8OtTnqSvNTO"
      },
      "source": [
        "# load the dataset with the faces\n",
        "dataset = fetch_olivetti_faces()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KrRyzXhvNTP"
      },
      "source": [
        "faces = dataset.data\n",
        "image_shape = ((64,64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkgRtN3mvNTP"
      },
      "source": [
        "n_samples, n_features = faces.shape\n",
        "new = faces.reshape((400,1,64*64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVW6_ws4vNTP"
      },
      "source": [
        "#show the 25 first faces\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "for x in range(0, 25):\n",
        "    image = new[x].reshape((image_shape))\n",
        "    vmax = max(image.max(), -image.min())\n",
        "    ax = plt.subplot(5,5,x+1)\n",
        "    plt.imshow(new[x].reshape((image_shape)),\n",
        "               cmap=plt.cm.gray,interpolation='nearest',vmin=-vmax, vmax=vmax)\n",
        "    plt.setp(ax.get_xticklabels(), visible=False)\n",
        "    plt.setp(ax.get_yticklabels(), visible=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaaOKW8dvNTP"
      },
      "source": [
        "#main loop for averaging\n",
        "#the total faces in the db are 400\n",
        "\n",
        "number_of_faces_to_average = 150\n",
        "\n",
        "#to get the average wee need to loop over the images,\n",
        "#sum them up and then divide by the number of elements\n",
        "average_face = np.zeros(image_shape, dtype=np.float32)\n",
        "\n",
        "for x in range(number_of_faces_to_average):\n",
        "    #add to the average\n",
        "    average_face = np.add(average_face,faces[x].reshape(image_shape))\n",
        "average_face = np.divide(average_face,number_of_faces_to_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_jpYM9_vNTP"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.imshow(average_face, \n",
        "           cmap=plt.cm.gray,\n",
        "           interpolation='nearest',\n",
        "           vmin=-vmax, \n",
        "           vmax=vmax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xh3HcsZvNTP"
      },
      "source": [
        "### <font color='red'>Task 4</font>\n",
        "Change the value of the variable **number_of_faces_to_average** to see how it affects the average face image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYOiWNgRvNTQ"
      },
      "source": [
        "# Complete the code for task 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYHjVMEEvNTQ"
      },
      "source": [
        "### 3.4 Histogram based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knhZB3MRvNTQ"
      },
      "source": [
        "Histogram is an array that shows the distribution of the pixel values for an image. For an 8-bit grayscale images, there are $2^8=256$ possible different values for each pixel. The histogram of such an image, will consist of an 1D array h of size 256, where h[i]=x means that there are exactly x pixels in the image that take the value i. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZIdV6tbvNTQ"
      },
      "source": [
        "hist = np.zeros(256)\n",
        "\n",
        "for (x,y),value in np.ndenumerate(flower.astype(np.uint8)):\n",
        "    hist[int(value)] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCRYTYWJvNTQ"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.subplot(121, aspect='equal')\n",
        "plt.imshow(flower.astype(np.uint8), cmap=plt.cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.title('Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.subplot(122)\n",
        "plt.plot(hist)\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3lYMI3yvNTQ"
      },
      "source": [
        "Plot the 3-component histogram for the colour image flower. You can create three new grayscale images from the 3 planes of the colour image (r,g,b) and then plot a histogram for each one of them. (Note: You can use fuction 'np.histogram(r.flatten(),256)' to get each component histogram for the colour image flower)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-AMWvYLvNTQ"
      },
      "source": [
        "#load the rgb version of image\n",
        "flower = rgb.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUHw0N5avNTR"
      },
      "source": [
        "r = flower[:,:,0];\n",
        "g = flower[:,:,1];\n",
        "b = flower[:,:,2];\n",
        "\n",
        "\n",
        "#show the images\n",
        "fig = plt.figure(0)\n",
        "plt.subplots_adjust(hspace = 1)\t\n",
        "plt.subplot(431, aspect='equal')\n",
        "plt.imshow(r.astype(np.uint8), cmap=plt.cm.Greys_r,aspect='equal')\n",
        "plt.title('r')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "#show the images\n",
        "fig = plt.figure(0)\n",
        "plt.subplot(432, aspect='equal')\n",
        "plt.imshow(g.astype(np.uint8), cmap=plt.cm.Greys_r,aspect='equal')\n",
        "plt.title('g')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "#show the images\n",
        "fig = plt.figure(0)\n",
        "plt.subplot(433, aspect='equal')\n",
        "plt.imshow(b.astype(np.uint8), cmap=plt.cm.Greys_r,aspect='equal')\n",
        "plt.title('b')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "\n",
        "plt.subplot(512)\n",
        "plt.xlim([0,255])\n",
        "plt.hist(r.flatten(),bins=256,color='r')\n",
        "plt.title('r histogram')\n",
        "\n",
        "\n",
        "plt.subplot(513)\n",
        "plt.xlim([0,255])\n",
        "plt.hist(g.flatten(),bins=256,color='g')\n",
        "plt.title('g histogram')\n",
        "\n",
        "plt.subplot(514)\n",
        "plt.xlim([0,255])\n",
        "plt.hist(b.flatten(),bins=256,color='b')\n",
        "plt.title('b histogram')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDBeNpjGvNTR"
      },
      "source": [
        "Plot and compare the histogram for the original, flipped and inversed flower images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSqxaeOFvNTR"
      },
      "source": [
        "flower = gray.copy()\n",
        "\n",
        "hist = np.zeros(256)\n",
        "hist_flipped = np.zeros(256)\n",
        "hist_inverse = np.zeros(256)\n",
        "\n",
        "for (x,y),value in np.ndenumerate(flower):\n",
        "    hist[int(value)] = hist[int(value)]+1   \n",
        "\n",
        "for (x,y),value in np.ndenumerate(flipped_vertical_arr):\n",
        "    hist_flipped[int(value)] = hist_flipped[int(value)]+1    \n",
        "\n",
        "for (x,y),value in np.ndenumerate(inverse):\n",
        "    hist_inverse[int(value)] = hist_inverse[int(value)]+1 \n",
        "    \n",
        "    \n",
        "#show the images\n",
        "fig = plt.figure(0)\n",
        "plt.subplots_adjust(hspace = 1)\t\n",
        "plt.subplot(141, aspect='equal')\n",
        "plt.imshow(flower.astype(np.uint8), cmap=plt.cm.Greys_r,aspect='equal')\n",
        "plt.title('Orignal flower')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.xlim([0,255])\n",
        "plt.plot(hist)\n",
        "plt.title('Orignal flower  histogram')\n",
        "\n",
        "#show the images\n",
        "plt.subplot(143)\n",
        "plt.xlim([0,255])\n",
        "plt.plot(hist_flipped)\n",
        "plt.title('flipped flower histogram')\n",
        "\n",
        "#show the images\n",
        "plt.subplot(144)\n",
        "plt.xlim([0,255])\n",
        "plt.plot(hist_inverse)\n",
        "plt.title('inverse flower histogram')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KDWRgtXvNTR"
      },
      "source": [
        "### 3.5 Histogram equalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdAPWOXivNTS"
      },
      "source": [
        "Histogram is a powerful tool because it gives us the general view of the image, and we can use it in order to utilize several transformations on that image. Here we will see how we can use it to make an image with low contrast reveal the information it hides. \n",
        "\n",
        "![Figure1](https://raw.githubusercontent.com/wOOL/COM2028/master/W1/moon_original.png)\n",
        "\n",
        "In this figure, we can see a standard test image for histogram based algorithms, the moon image. The poor contrast makes it difficult to get the details of the image. \n",
        "\n",
        "In order to understand the method that is used to improve the quality of this image, we need to be familiar with another thing except the histogram: the cumulative distribution function. The cumulative histogram, supposing the we already have computed the histogram $hist$ can be defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "c\\_hist(x) = \\displaystyle\\sum\\limits_{i=1}^x hist(i)\n",
        "\\end{equation}\n",
        "\n",
        "This new array F holds information that shows how many pixels in the image have values equal or less to a specific value x. So if we want to find out how many pixels in our image have value less than 200, we need to find the value of $c\\_hist(200)$. \n",
        "\n",
        "However we can use the information from the cumulative histogram, to make the histogram more spread along the $256$ different values that it can take. First of all, we can to normalise the values of the $c\\_hist$ so that they are between $[0,255]$. This can be simply done by \n",
        "\n",
        "\\begin{equation}\n",
        "c\\_hist_{normalised}(x) = \\frac{256 \\times c\\_hist(x)}{max(c\\_hist)}\n",
        "\\end{equation}\n",
        "\n",
        "If we only keep the integer part for the normalized values, then the values of the $c\\_hist_{normalised}(x)$ will be from $[0,255]$. This allows as to use them as a mapping function. So the algorithm that we will use for histogram equalization is just to remap each pixel of the image, to a new value based on the information that $c\\_hist_{normalised}(x)$ holds. For example if the $c\\_hist_{normalised}(100) = 150$, this means that all the pixels in the original image that have value of 100, should now take the value of 150. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL1xMS4AvNTS"
      },
      "source": [
        "from skimage.data import moon\n",
        "plt.rcParams['figure.figsize'] = [20, 10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWjGSgvlvNTS"
      },
      "source": [
        "#load the moon image: it is a low contrast image\n",
        "moon = moon()\n",
        "imhist, _ = np.histogram(moon.flatten(), 256)\n",
        "#compute the cumulative distribution\n",
        "cdf = imhist.cumsum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkUXL3pcvNTS"
      },
      "source": [
        "#create the pixel equalization transform \n",
        "cdf = 255 * cdf / cdf[255] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9isqnE0vNTT"
      },
      "source": [
        "#create a new image to hold the equalized\n",
        "moon_equalized = np.empty_like(moon)\n",
        "for (x,y), pixel_value in np.ndenumerate(moon):\n",
        "    moon_equalized[x,y] = cdf[pixel_value]\n",
        "    \n",
        "#get the info for the equalized image\n",
        "imhist_eq, _ = np.histogram(moon_equalized.flatten(),256)\n",
        "cdf_eq = imhist_eq.cumsum() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kfQt-KvNTT"
      },
      "source": [
        "#plot the images\n",
        "plt.figure(0)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(moon.astype(np.uint8),\n",
        "cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.subplot(1,2,2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(moon_equalized.astype(np.uint8),\n",
        "cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "\n",
        "#plot the info\n",
        "plt.figure(1)\n",
        "plt.subplots_adjust(wspace=1, hspace=1)\n",
        "x = np.arange(0,256)\n",
        "\n",
        "plt.subplot(4,1,1)\n",
        "plt.title('The PDF of the equalized moon image (histogram)')\n",
        "plt.xlim([0,255])\n",
        "plt.bar(x,imhist)\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(cdf)\n",
        "plt.title('The CDF of the equalized moon image')\n",
        "plt.xlim([0,255])\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.title('The PDF of the equalized moon image (histogram)')\n",
        "plt.xlim([0,255])\n",
        "plt.plot(imhist_eq)\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(cdf_eq)\n",
        "plt.title('The CDF of the equalized moon image')\n",
        "plt.xlim([0,255])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4URK0gHbvNTT"
      },
      "source": [
        "### 3.6 Convolution based methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1f_bteSvNTT"
      },
      "source": [
        "The discrete convolution that we will use in this lab is a process of using with a kernel $K$ of size $n\\times n$, on an image $I$ of size $m\\times l$ that returns an new image $C$. To compute the value of this new image in the pixel $x,y$ we use the following equation:\n",
        "\n",
        "\\begin{equation}\n",
        "C(x,y) = \\sum\\limits_{q=-w}^{w} \\sum\\limits_{p=-w}^{w} I(x-q,y-p) \\cdot K(q,p)\n",
        "\\label{equation:convolution}\n",
        "\\end{equation}\n",
        "\n",
        "where $w=(n-1)/2$.\n",
        "The example below clarifies the process of the convolution, using a sample image $I$ and a mask $K$.\n",
        "\n",
        "\\begin{equation} \n",
        "I=\n",
        "\\begin{pmatrix}\n",
        "10 & 20 & 25 & \\cdots & \\cdots \\\\\n",
        "11 & \\underline{22} & 33 & \\cdots & \\cdots \\\\\n",
        "44 & 50 & 90 & \\cdots & \\cdots\\\\\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "\n",
        "\\begin{equation} \n",
        "K= \\frac{1}{9} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1 & 2 & 1 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "1 & 2 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "\n",
        "We want to apply the convolution mask to the pixel which is underlined, with value 22. According to the equation, the new value of this pixel will be:\n",
        "\n",
        "\n",
        "\\begin{equation} \n",
        "\\frac{1}{9} \\{ 1 \\cdot 10 + 2 \\cdot 20 + 1 \\cdot 25 + 0 \\cdot 11+ 1 \\cdot 22+ 0 \\cdot 33+ 1 \\cdot 44+ 2 \\cdot 50 + 1 \\cdot 90 \\}= 36\n",
        "\\end{equation} \n",
        "\n",
        "So in the new convoluted image that we will call $C$, the element in the same position as the anchor point in the original image (the squared 22), will become 36.\n",
        "\n",
        "\\begin{equation} \n",
        "C=\n",
        "\\begin{pmatrix}\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
        "\\cdots & \\underline{36} & \\cdots & \\cdots & \\cdots \\\\\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
        "\\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "That means that for an image of size [128,128] and a kernel of size [3,3] to get the convolved image we need to perform $128 \\times 128 \\times 9$ operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7i-sKkRvNTT"
      },
      "source": [
        "In the following code program, you will find a simple implementation of a convolution. The flower image, is convoluted with the kernel $K$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPdyZqWgvNTU"
      },
      "source": [
        "flower = gray.copy()\n",
        "(w,h) = flower.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2p0mdpDvNTU"
      },
      "source": [
        "norm_factor = 1.0/21.0 \n",
        "kernel = norm_factor * np.array([[1, 3, 1],\n",
        "                   [3, 5, 3], \n",
        "                   [1, 3, 1]])  \n",
        "\n",
        "convoluted = np.empty_like(flower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRIQUYPXvNTU"
      },
      "source": [
        "#slow unoptimzed code\n",
        "for x in range(1,w-1):\n",
        "    for y in range(2,h-1):\n",
        "        convoluted[x,y] = kernel[0,0]* flower[x-1,y-1] + kernel[0,1]* flower[x-1,y] \\\n",
        "        + kernel[0,2]* flower[x-1,y+1] + kernel[1,0]* flower[x,y-1] + kernel[1,1]* flower[x,y] \\\n",
        "        + kernel[1,2]* flower[x,y+1] + kernel[2,0]* flower[x+1,y-1] + kernel[2,1]* flower[x+1,y]\\\n",
        "        + kernel[2,2]* flower[x+1,y+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beaDQjzLvNTU"
      },
      "source": [
        "#fix the overflows\n",
        "convoluted[convoluted>255]=255\n",
        "convoluted[convoluted<0]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvJFGKPUvNTU"
      },
      "source": [
        "#plot the images\n",
        "plt.figure(0)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(flower.astype(np.uint8),\n",
        "cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.subplot(1,2,2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(convoluted.astype(np.uint8),\n",
        "cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndHPtzSivNTU"
      },
      "source": [
        "### The following code apply Kernel to color image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIKv1EM5vNTV"
      },
      "source": [
        "flower = rgb.copy().astype(np.float32)\n",
        "(w,h,d) = flower.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlzVuAyPvNTV"
      },
      "source": [
        "norm_factor = 1.0\n",
        "kernel = norm_factor * np.array([[1, 2, 1],\n",
        "                   [0, 0, 0], \n",
        "                   [-1, -2, -1]]) \n",
        "convoluted = np.empty_like(flower)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxqvSChjvNTV"
      },
      "source": [
        "#slow unoptimzed code\n",
        "for x in range(1,w-1):\n",
        "    for y in range(2,h-1):\n",
        "        convoluted[x,y] = kernel[0,0]* flower[x-1,y-1] \\\n",
        "         + kernel[0,1]* flower[x-1,y] \\\n",
        "         + kernel[0,2]* flower[x-1,y+1] \\\n",
        "         + kernel[1,0]* flower[x,y-1] \\\n",
        "         + kernel[1,1]* flower[x,y] \\\n",
        "         + kernel[1,2]* flower[x,y+1] \\\n",
        "         + kernel[2,0]* flower[x+1,y-1] \\\n",
        "         + kernel[2,1]* flower[x+1,y] \\\n",
        "         + kernel[2,2]* flower[x+1,y+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNLq5ydTvNTV"
      },
      "source": [
        "# #fix the overflows\n",
        "convoluted[convoluted>255]=255\n",
        "convoluted[convoluted<0]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMTMhr4BvNTV"
      },
      "source": [
        "#plot the images\n",
        "plt.figure(0)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(flower.astype(np.uint8),\n",
        "           cmap=cm.Greys_r,aspect='equal',vmin=0,vmax=255)\n",
        "plt.subplot(1,2,2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(convoluted.astype(np.uint8),\n",
        "           cmap=cm.Greys_r,aspect='equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WMdRvXHvNTV"
      },
      "source": [
        "### Try it yourself\n",
        "Run the code in the colour flower image, using the kernels below. You can also experiment with your own kernels, by putting in random numbers and seeing the results.\n",
        "\n",
        "Below are some important kernels.\n",
        "\n",
        "\\begin{equation} \n",
        "motion= \\frac{1}{3} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\\begin{equation} \n",
        "sharpen=\n",
        "\\begin{pmatrix}\n",
        "0 & -1 & 0 \\\\\n",
        "-1 & 4 & -1 \\\\\n",
        "0 & -1 & 0\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "\\begin{equation} \n",
        "laplacian=\n",
        "\\begin{pmatrix}\n",
        "-1 & -1 & -1 \\\\\n",
        "-1 & 8 & -1 \\\\\n",
        "-1 & -1 & -1\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "\\begin{equation} \n",
        "emboss =\n",
        "\\begin{pmatrix}\n",
        "-2 & -1 & 0 \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "0 & 1 & 2\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\n",
        "\\begin{equation} \n",
        "edge= \\frac{1}{8} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1 & 2 & 1 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "1 & 2 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n",
        "\\begin{equation} \n",
        "gaussian=\\frac{1}{21} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1 & 3 & 1 \\\\\n",
        "3 & 5 & 3 \\\\\n",
        "1 & 3 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation} \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKF0cixhvNTW"
      },
      "source": [
        "# Try the code for different kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge Part: Median house prices\n",
        "\n",
        "**Example scenario:** You are a Californian estate agent trying to identify the best suburbs and houses for median sale price, so you can actively focus on these high-value areas and properties... Especially since your commission is based on sale price.\n",
        "\n",
        "**Task:** Create a estimator using a method of your choice (e.g. MLP, Linear Regression) to estimate median house price.\n",
        "\n",
        "Notes:\n",
        "- You may use any subset or all the features provided when training your model.\n",
        "- You may not need or want all features, and your model will train faster with a subset of the data.\n",
        "- You may want to use feature-wise normalisation of the dataset.\n",
        "- Remember to set your URN on Kaggle.\n",
        "- Kaggle link: https://www.kaggle.com/t/0645ec4bdd2d4bc6bdc9ccd14df1249b"
      ],
      "metadata": {
        "id": "pLTyN-VbLqFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'illyagloba'  # Your Kaggle username\n",
        "os.environ['KAGGLE_KEY'] = '0ffde78b85da69f118ad2bba242f7c45'  # Your Kaggle API key\n",
        "os.environ['URN'] = '6604778'  # Your URN: submissions without a URN will not count"
      ],
      "metadata": {
        "id": "6MkcQpoOMaWs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset:"
      ],
      "metadata": {
        "id": "sWh54DyyMeWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /usr/local/bin/kaggle competitions download -c uos-com2028-21-22-lab4 --force\n",
        "!unzip uos-com2028-21-22-lab4.zip"
      ],
      "metadata": {
        "id": "IM2lHBwcMftb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9566339c-953b-469f-a252-41d0caf9b667"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading uos-com2028-21-22-lab4.zip to /content\n",
            "100% 1.25M/1.25M [00:01<00:00, 956kB/s] \n",
            "100% 1.25M/1.25M [00:01<00:00, 970kB/s]\n",
            "Archive:  uos-com2028-21-22-lab4.zip\n",
            "  inflating: HouseTest.csv           \n",
            "  inflating: HouseTrain.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to load and process the data."
      ],
      "metadata": {
        "id": "c2x-97GJMpHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "training_house = pd.read_csv('HouseTrain.csv')\n",
        "testing_house = pd.read_csv('HouseTest.csv')\n",
        "\n",
        "print(f'Training set sample (target=Median_House_Value): \\n{training_house[:10]}\\n\\n')\n",
        "print(f'Testing set sample (target=Median_House_Value): \\n{testing_house[:3]}\\n\\n')\n",
        "\n",
        "# You may want to change which columns are used for a more efficient or better model...\n",
        "# Some features may not correlate well with our target...\n",
        "# You may also want to try feature-wise normalisation (e.g. sklearn.preprocessing.normalize, axis=0), which may help your model.\n",
        "columns = ['Median_Income',\n",
        "           'Median_Age',\n",
        "           'Tot_Rooms',\n",
        "           'Tot_Bedrooms',\n",
        "           'Population',\n",
        "           'Households',\n",
        "           'Latitude',\n",
        "           'Longitude',\n",
        "           'Distance_to_coast',\n",
        "           'Distance_to_LA',\n",
        "           'Distance_to_SanDiego',\n",
        "           'Distance_to_SanJose',\n",
        "           'Distance_to_SanFrancisco']\n",
        "\n",
        "X_train_house = training_house.loc[:, columns].values\n",
        "y_train_house = training_house.loc[:, 'Median_House_Value'].values\n",
        "X_test_house = testing_house.loc[:, columns].values\n",
        "\n",
        "print('Training sample shape', X_train_house.shape, 'example:', X_train_house[0])\n",
        "print('Training target shape', y_train_house.shape, 'example:', y_train_house[0])\n",
        "print('Testing sample shape', X_test_house.shape, 'example:', X_test_house[0])"
      ],
      "metadata": {
        "id": "miWcOxXgMrge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940aa952-ab54-47c5-cbf7-79acb60ef1e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set sample (target=Median_House_Value): \n",
            "   Median_House_Value  Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  \\\n",
            "0               65800         2.4044          34       1923           379   \n",
            "1              209100         4.2500          43        821           149   \n",
            "2               90300         2.0156          47        771           224   \n",
            "3              182500         4.0556           9       1739           358   \n",
            "4              328000         7.2861          24        962           146   \n",
            "5              268000         3.1359          27       3044           661   \n",
            "6              142600         4.3542          32       2215           351   \n",
            "7              252100         3.7433          25       7201          1521   \n",
            "8              168300         3.1300           8       2836           522   \n",
            "9              254500         4.5769          35       1791           322   \n",
            "\n",
            "   Population  Households  Latitude  Longitude  Distance_to_coast  \\\n",
            "0        1101         351     35.50    -119.28      123925.435568   \n",
            "1         370         135     37.37    -121.83       24412.997291   \n",
            "2         637         212     32.68    -117.10        4900.258413   \n",
            "3         820         323     34.31    -118.45       32946.220074   \n",
            "4         492         155     37.37    -121.81       25964.042139   \n",
            "5        1229         618     36.61    -121.92        4186.563957   \n",
            "6         771         311     33.95    -117.37       59928.525012   \n",
            "7        3264        1433     37.93    -122.07       13380.120512   \n",
            "8        1163         512     39.69    -121.56      178540.127492   \n",
            "9         988         304     37.73    -122.42        2888.376519   \n",
            "\n",
            "   Distance_to_LA  Distance_to_SanDiego  Distance_to_SanJose  \\\n",
            "0   186744.379665         365907.045368        310335.335108   \n",
            "1   490774.413273         669495.564155          6765.398418   \n",
            "2   185907.665331           6961.636904        676937.355898   \n",
            "3    34375.959046         213782.342288        457682.433868   \n",
            "4   489586.035388         668343.081459          8282.089127   \n",
            "5   438236.987419         613787.568083         80705.271037   \n",
            "6    81337.276076         138609.323431        555529.187454   \n",
            "7   551632.213014         730841.340570         67919.617695   \n",
            "8   692690.696700         869864.116003        263408.573266   \n",
            "9   555544.136870         733932.475740         63903.431680   \n",
            "\n",
            "   Distance_to_SanFrancisco  \n",
            "0             378103.314216  \n",
            "1              69469.617747  \n",
            "2             744912.843099  \n",
            "3             525716.518083  \n",
            "4              70823.350953  \n",
            "5             137122.484983  \n",
            "6             623366.032038  \n",
            "7              36156.128222  \n",
            "8             226056.903503  \n",
            "9               4989.320967  \n",
            "\n",
            "\n",
            "Testing set sample (target=Median_House_Value): \n",
            "   Id  Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  Population  \\\n",
            "0   0         2.1542          27       1782           560        1785   \n",
            "1   1         5.3124          52       1979           359         648   \n",
            "2   2         3.6196           5       3344           800        1341   \n",
            "\n",
            "   Households  Latitude  Longitude  Distance_to_coast  Distance_to_LA  \\\n",
            "0         560     32.66    -117.10        3703.146429   187744.060243   \n",
            "1         370     37.79    -122.44        1016.672627   561582.815087   \n",
            "2         670     38.49    -121.52       46085.892162   574149.763045   \n",
            "\n",
            "   Distance_to_SanDiego  Distance_to_SanJose  Distance_to_SanFrancisco  \n",
            "0           8431.575916        678672.245622             746642.002460  \n",
            "1         740065.842036         69847.263158               1939.416481  \n",
            "2         753125.271689        132481.662149             112658.639348  \n",
            "\n",
            "\n",
            "Training sample shape (18576, 13) example: [ 2.40440000e+00  3.40000000e+01  1.92300000e+03  3.79000000e+02\n",
            "  1.10100000e+03  3.51000000e+02  3.55000000e+01 -1.19280000e+02\n",
            "  1.23925436e+05  1.86744380e+05  3.65907045e+05  3.10335335e+05\n",
            "  3.78103314e+05]\n",
            "Training target shape (18576,) example: 65800\n",
            "Testing sample shape (2064, 13) example: [ 2.15420000e+00  2.70000000e+01  1.78200000e+03  5.60000000e+02\n",
            "  1.78500000e+03  5.60000000e+02  3.26600000e+01 -1.17100000e+02\n",
            "  3.70314643e+03  1.87744060e+05  8.43157592e+03  6.78672246e+05\n",
            "  7.46642002e+05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now create and train your model:"
      ],
      "metadata": {
        "id": "DZGJi954Odd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "lr = Ridge(alpha=3.5)\n",
        "lr.fit(X_train_house, y_train_house)\n",
        "lr = LinearRegression().fit(X_train_house, y_train_house)\n",
        "\n",
        "\n",
        "lr.score(X_train_house, y_train_house)\n",
        "predictions = lr.predict(X_test_house)\n",
        "predictions.shape\n",
        "type(predictions)\n"
      ],
      "metadata": {
        "id": "z_7cEB0LN7sl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1233a54c-0507-45cf-f3e3-cc360c4c7e2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to estimate based on testing set:"
      ],
      "metadata": {
        "id": "Y5gNi6oKeSYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = lr.score(X_test_house, predictions)\n",
        "result"
      ],
      "metadata": {
        "id": "MkqqWta_eVaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d735fa-6d52-4dad-d3a9-abba46b5f8ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your predictions CSV:"
      ],
      "metadata": {
        "id": "-mJPACi-c1RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={'Median_House_Value': predictions}).to_csv('predictions.csv', index_label='Id')"
      ],
      "metadata": {
        "id": "H6HpkrHzcSqa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And upload to Kaggle:"
      ],
      "metadata": {
        "id": "D6u1FuBwc4R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /usr/local/bin/kaggle competitions submit -m $URN -c uos-com2028-21-22-lab4 -f predictions.csv"
      ],
      "metadata": {
        "id": "IuVoZoJTcyAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3c8afc-ed1a-4286-9dc2-19be2ebe32f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 46.4k/46.4k [00:04<00:00, 9.87kB/s]\n",
            "Successfully submitted to COM2028 21/22 Lab 4"
          ]
        }
      ]
    }
  ]
}